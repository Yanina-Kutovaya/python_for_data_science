{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Спортивный анализ данных. Платформа Kaggle\n",
    "### Feature Engineering, Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практическое задание 4.\n",
    "\n",
    "* __Задание 0:__ выбрать любую модель машнного обучения и зафиксировать любой тип валидации. Обучить базовую модель и зафиксировать базовое качество модели. В каждом следующем задании нужно будет обучить выбранную модель и оценивать ее качество на зафиксированной схеме валидации. После каждого задания, требуется сделать вывод о достигаемом качестве модели, по сравнению с качестом из предыдущего шага.\n",
    "\n",
    "* __Задание 1:__ признак TransactionDT - это смещение в секундах относительно базовой даты. Базовая дата - 2017-12-01, преобразовать признак TransactionDT в datetime, прибавив к базовой дате исходное значение признака. Из полученного признака выделить год, месяц, день недели, час, день.\n",
    "\n",
    "* __Задание 2:__ сделать конкатенацию признаков\n",
    "* card1 + card2;\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "\n",
    "* Рассматривать их как категориальных признаки.\n",
    "\n",
    "* __Задание 3:__ Сделать FrequencyEncoder для признаков card1 - card6, addr1, addr2.\n",
    "\n",
    "* __Задание 4:__ Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2.\n",
    "\n",
    "* __Задание 5:__ Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2.\n",
    "\n",
    "* __Задание 6:__ выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt\n",
    "\n",
    "* __Задание 7 (опция):__ выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков.\n",
    "\n",
    "\n",
    "Ссылка на данные - https://drive.google.com/file/d/1GN6d4_QTYWY-qFdjz_TqxFHIJRi_oTRP/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from time import mktime\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy.stats import probplot, ks_2samp\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пути к директориям и файлам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'C:/Users/ASER/Desktop/GeekBrains/Kaggle/Lesson_2/data/'\n",
    "TRAIN_DATASET_PATH = PATH + 'train.csv'\n",
    "TEST_DATASET_PATH = PATH + 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape (180000, 394)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[2 rows x 394 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "print('train.shape', train.shape)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.shape (100001, 394)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3287000</td>\n",
       "      <td>1</td>\n",
       "      <td>7415038</td>\n",
       "      <td>226.0</td>\n",
       "      <td>W</td>\n",
       "      <td>12473</td>\n",
       "      <td>555.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3287001</td>\n",
       "      <td>0</td>\n",
       "      <td>7415054</td>\n",
       "      <td>3072.0</td>\n",
       "      <td>W</td>\n",
       "      <td>15651</td>\n",
       "      <td>417.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        3287000        1        7415038           226.0         W  12473   \n",
       "1        3287001        0        7415054          3072.0         W  15651   \n",
       "\n",
       "   card2  card3 card4  card5  ... V330  V331  V332  V333  V334 V335 V336  \\\n",
       "0  555.0  150.0  visa  226.0  ...  NaN   NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "1  417.0  150.0  visa  226.0  ...  NaN   NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "\n",
       "   V337  V338  V339  \n",
       "0   NaN   NaN   NaN  \n",
       "1   NaN   NaN   NaN  \n",
       "\n",
       "[2 rows x 394 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(TEST_DATASET_PATH)\n",
    "print('test.shape', test.shape)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'isFraud'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обзор распределения целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    174859\n",
       "1      5141\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[TARGET_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Классификация признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TransactionDT', 'TransactionAmt', 'ProductCD']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEPENDENT_VARIABLE_NAMES = train.columns.to_list()[2:]\n",
    "INDEPENDENT_VARIABLE_NAMES[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numerical features 378\n",
      "count of categorical features 14\n"
     ]
    }
   ],
   "source": [
    "NUMERICAL_FEATURE_NAMES = train[INDEPENDENT_VARIABLE_NAMES].select_dtypes(include=[np.number]).columns.to_list()\n",
    "CATEGORICAL_FEATURE_NAMES = train[INDEPENDENT_VARIABLE_NAMES].select_dtypes(include=[np.object]).columns.to_list()\n",
    "\n",
    "print(f'count of numerical features {len(NUMERICAL_FEATURE_NAMES)}')\n",
    "print(f'count of categorical features {len(CATEGORICAL_FEATURE_NAMES)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self, CATEGORICAL_FEATURE_NAMES):\n",
    "        self.CATEGORICAL_FEATURE_NAMES = CATEGORICAL_FEATURE_NAMES\n",
    "        self.NEW_CATEGORICAL_FEATURE_NAMES = []\n",
    "        self.LGB_CATEGORICAL_FEATURE_NAMES = []\n",
    "        self.target_encodings = dict()\n",
    "        self.ordinal_encoding = dict()\n",
    "        \n",
    "        \n",
    "    def fit(self, train):\n",
    "        df = train.copy()\n",
    "        for feature in self.CATEGORICAL_FEATURE_NAMES: \n",
    "            new_feature = feature + '_'\n",
    "            lgb_feature = feature + 'lgb'\n",
    "            self.NEW_CATEGORICAL_FEATURE_NAMES.append(new_feature)\n",
    "            self.LGB_CATEGORICAL_FEATURE_NAMES.append(lgb_feature)            \n",
    "            self.target_encodings[feature] = {}\n",
    "            self.ordinal_encoding[feature] = {}\n",
    "            for ind, level in enumerate(df[feature].unique()):\n",
    "                level_value = df.loc[df[feature]==level, TARGET_NAME].mean()\n",
    "                self.target_encodings[feature][level] = level_value\n",
    "                self.ordinal_encoding[feature][level] = ind\n",
    "                \n",
    "                \n",
    "    def transform(self, df):\n",
    "        for feature in self.CATEGORICAL_FEATURE_NAMES: \n",
    "            for level in self.target_encodings[feature].keys():\n",
    "                new_feature = feature + '_'\n",
    "                lgb_feature = feature + 'lgb'\n",
    "                df.loc[df[feature] == level, new_feature] = self.target_encodings[feature][level]\n",
    "                df.loc[df[feature] == level, lgb_feature] = self.ordinal_encoding[feature][level]\n",
    "                \n",
    "        df[CATEGORICAL_FEATURE_NAMES] = df[CATEGORICAL_FEATURE_NAMES].astype(str)  \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.sort_values(by=['TransactionDT'])\n",
    "df_train = df.loc[:125999, :]\n",
    "df_valid = df.loc[126000:152999, :]\n",
    "df_test = df.loc[153000:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Генерация признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a) oбучающий датасет + отложеная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureGenerator(CATEGORICAL_FEATURE_NAMES)\n",
    "features.fit(df_train)\n",
    "df_train = features.transform(df_train)\n",
    "df_valid = features.transform(df_valid)\n",
    "df_test = features.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b) тестовый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureGenerator(CATEGORICAL_FEATURE_NAMES)\n",
    "features.fit(train)\n",
    "train = features.transform(train)\n",
    "test = features.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_FEATURE_NAMES = NUMERICAL_FEATURE_NAMES + features.NEW_CATEGORICAL_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\"booster\": \"gbtree\", \n",
    "              \"objective\": \"binary:logistic\", \n",
    "              \"eval_metric\": \"auc\", \n",
    "              \"learning_rate\": 0.2,               \n",
    "              \"reg_lambda\": 100, \n",
    "              \"max_depth\": 4, \n",
    "              \"gamma\": 10, \n",
    "              \"nthread\": 6, \n",
    "              \"seed\": 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    dtrain = xgb.DMatrix(data=df_train[SELECTED_FEATURE_NAMES], label=df_train[TARGET_NAME])\n",
    "    dvalid = xgb.DMatrix(data=df_valid[SELECTED_FEATURE_NAMES], label=df_valid[TARGET_NAME])\n",
    "    dtest = xgb.DMatrix(data=df_test[SELECTED_FEATURE_NAMES], label=df_test[TARGET_NAME])\n",
    "\n",
    "    model_xgb = xgb.train(params=params_xgb,\n",
    "                          dtrain=dtrain,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=50,\n",
    "                          evals=[(dtrain, \"train\"), (dvalid, \"valid\"), (dtest, \"test\")],\n",
    "                          verbose_eval=50,\n",
    "                          maximize=True)\n",
    "\n",
    "    dtest_final = xgb.DMatrix(data=test[SELECTED_FEATURE_NAMES])\n",
    "\n",
    "    y_pred = model_xgb.predict(dtest_final, ntree_limit=model_xgb.best_ntree_limit)\n",
    "    score = roc_auc_score(test[TARGET_NAME], y_pred)\n",
    "    print(f'roc-auc score of prediction: {round(score, 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Базовая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61787\ttest-auc:0.62465\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91110\tvalid-auc:0.88956\ttest-auc:0.87570\n",
      "[100]\ttrain-auc:0.91960\tvalid-auc:0.89530\ttest-auc:0.88086\n",
      "Stopping. Best iteration:\n",
      "[86]\ttrain-auc:0.91863\tvalid-auc:0.89538\ttest-auc:0.88172\n",
      "\n",
      "roc-auc score of prediction: 0.86895\n"
     ]
    }
   ],
   "source": [
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Признак TransactionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_TransactionDT(data):\n",
    "    t = t0 + pd.to_timedelta(data['TransactionDT'], unit='s')\n",
    "    data.loc[:, 'year'] = t.dt.year\n",
    "    data.loc[:, 'month'] = t.dt.month\n",
    "    data.loc[:, 'weekday'] = t.dt.weekday\n",
    "    data.loc[:, 'hour'] = t.dt.hour\n",
    "    data.loc[:, 'day'] = t.dt.day \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.strptime('2017-12-01', \"%Y-%m-%d\")\n",
    "\n",
    "df_list = [df_train, df_valid, df_test, test]\n",
    "for df in df_list:\n",
    "    df = transform_TransactionDT(df)\n",
    "    \n",
    "TIME_FEATURE_NAMES = ['year', 'month', 'weekday', 'hour', 'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61787\ttest-auc:0.62465\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91000\tvalid-auc:0.88901\ttest-auc:0.87229\n",
      "[100]\ttrain-auc:0.91854\tvalid-auc:0.89632\ttest-auc:0.88231\n",
      "Stopping. Best iteration:\n",
      "[81]\ttrain-auc:0.91854\tvalid-auc:0.89632\ttest-auc:0.88231\n",
      "\n",
      "roc-auc score of prediction: 0.86449\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES.remove('TransactionDT')\n",
    "SELECTED_FEATURE_NAMES += TIME_FEATURE_NAMES    \n",
    "run_model()\n",
    "\n",
    "# roc-auc score of prediction base: 0.86895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Замена признака TransactionDT на признаки year, month, weekday, hour, day не улучшила качество предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Соединение признаков\n",
    "* card1 + card2;\n",
    "\n",
    "* card1 + card2 + card_3 + card_5;\n",
    "\n",
    "* card1 + card2 + card_3 + card_5 + addr1 + addr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(data, concat_lists, NEW_FEATURE_NAMES):\n",
    "    for i, cols in enumerate(concat_lists):\n",
    "        if i > 0:        \n",
    "            cols = [NEW_FEATURE_NAMES[i - 1]] + cols\n",
    "        data.loc[:, NEW_FEATURE_NAMES[i]] = data.loc[:, cols].\\\n",
    "                    apply(lambda x: ''.join(str(x.values))[1:-1].replace(\"'\", \"\"), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder: \n",
    "    def __init__(self, features_list):\n",
    "        self.features_list = features_list\n",
    "        self.NEW_FEATURE_NAMES = []\n",
    "        self.freq = {}\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, data):\n",
    "        for feature in self.features_list:\n",
    "            name_str = feature + '_freq'\n",
    "            self.NEW_FEATURE_NAMES.append(name_str)\n",
    "            \n",
    "            self.freq[feature] = data[feature].value_counts() \n",
    "            \n",
    "            for i, value in enumerate(self.freq[feature].keys()):\n",
    "                data.loc[data[feature] == value, name_str] = self.freq[feature].values[i]               \n",
    "    \n",
    "        return data\n",
    "    \n",
    "    def transform(self, data):\n",
    "        for feature in self.features_list:\n",
    "            name_str = feature + '_freq'\n",
    "            for i, value in enumerate(self.freq[feature].keys()):                \n",
    "                data.loc[data[feature] == value, name_str] = self.freq[feature].values[i] \n",
    "                \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_lists = [['card1', 'card2'], ['card3', 'card5'], ['addr1', 'addr2']]\n",
    "NEW_FEATURE_NAMES = ['card1_2', 'card1_2_3_5', 'card1_2_3_5_addr1_2']\n",
    "\n",
    "for df in df_list:\n",
    "    df = merge_features(df, concat_lists, NEW_FEATURE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_encoder = FrequencyEncoder(NEW_FEATURE_NAMES)\n",
    "df_train = freq_encoder.fit_transform(df_train)\n",
    "for df in df_list[1:]:\n",
    "    df = freq_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61787\ttest-auc:0.62465\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91029\tvalid-auc:0.89099\ttest-auc:0.87708\n",
      "[100]\ttrain-auc:0.91803\tvalid-auc:0.89608\ttest-auc:0.88284\n",
      "Stopping. Best iteration:\n",
      "[77]\ttrain-auc:0.91756\tvalid-auc:0.89619\ttest-auc:0.88311\n",
      "\n",
      "roc-auc score of prediction: 0.86478\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES += freq_encoder.NEW_FEATURE_NAMES\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Соединение признаков card1 + card2; card1 + card2 + card_3 + card_5; card1 + card2 + card_3 + card_5 + addr1 + addr2\n",
    "особо не добавляет точности предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Frequency encoding - признаки card1 - card6, addr1, addr2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2']\n",
    "\n",
    "freq_encoder = FrequencyEncoder(features_list)\n",
    "df_train = freq_encoder.fit_transform(df_train)\n",
    "for df in df_list[1:]:\n",
    "    df = freq_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61787\ttest-auc:0.62465\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91299\tvalid-auc:0.89223\ttest-auc:0.87639\n",
      "[100]\ttrain-auc:0.92198\tvalid-auc:0.89860\ttest-auc:0.88215\n",
      "Stopping. Best iteration:\n",
      "[81]\ttrain-auc:0.92174\tvalid-auc:0.89855\ttest-auc:0.88258\n",
      "\n",
      "roc-auc score of prediction: 0.86795\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES += freq_encoder.NEW_FEATURE_NAMES\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Frequency encoding признаков card1 - card6, addr1, addr2 улушает качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. TransactionAmt\n",
    "\n",
    "Создать признаки на основе отношения: TransactionAmt к вычисленной статистике. Статистика - среднее значение / стандартное отклонение TransactionAmt, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositFeatures:\n",
    "    def __init__(self, base_feature, features_list):\n",
    "        self.base_feature = base_feature\n",
    "        self.features_list = features_list\n",
    "        self.NEW_FEATURE_NAMES = []\n",
    "        self.stat = {}\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, data):\n",
    "        for feature in self.features_list:\n",
    "            df = data[[self.base_feature, feature]]            \n",
    "            self.stat[feature] = df.groupby(feature).mean() / df.groupby(feature).std()\n",
    "            \n",
    "            name_str_1 = 'stat_' + feature\n",
    "            for i in self.stat[feature].index:            \n",
    "                df.loc[df[feature] == i, name_str_1] = self.stat[feature].loc[i, base_feature]\n",
    "\n",
    "            name_str_2 =  base_feature + '_' + name_str_1\n",
    "            self.NEW_FEATURE_NAMES.append(name_str_2)\n",
    "            \n",
    "            data[name_str_2] = df[base_feature] / df[name_str_1]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def transform(self, data):\n",
    "        for feature in self.features_list:\n",
    "            df = data[[self.base_feature, feature]]\n",
    "            \n",
    "            name_str_1 = 'stat_' + feature\n",
    "            for i in self.stat[feature].index:            \n",
    "                    df.loc[df[feature] == i, name_str_1] = self.stat[feature].loc[i, base_feature]\n",
    "                    \n",
    "            name_str_2 =  base_feature + '_' + name_str_1            \n",
    "            data[name_str_2] = df[base_feature] / df[name_str_1]\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list += ['card1_2', 'card1_2_3_5', 'card1_2_3_5_addr1_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature = 'TransactionAmt'\n",
    "comp_features = CompositFeatures(base_feature, features_list)\n",
    "df_train = comp_features.fit_transform(df_train)\n",
    "for df in df_list[1:]:\n",
    "    df = comp_features.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61788\ttest-auc:0.62471\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91376\tvalid-auc:0.89168\ttest-auc:0.87725\n",
      "[100]\ttrain-auc:0.92004\tvalid-auc:0.89508\ttest-auc:0.88188\n",
      "Stopping. Best iteration:\n",
      "[71]\ttrain-auc:0.92004\tvalid-auc:0.89508\ttest-auc:0.88188\n",
      "\n",
      "roc-auc score of prediction: 0.86443\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES += comp_features.NEW_FEATURE_NAMES\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Новые признаки на базе TransactionAmt не улучшают точность предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. D15\n",
    "Создать признаки на основе отношения: D15 к вычисленной статистике. Статистика - среднее значение / стандартное отклонение D15, сгруппированное по card1 - card6, addr1, addr2, и по признакам, созданным в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature = 'D15'\n",
    "comp_features = CompositFeatures(base_feature, features_list)\n",
    "df_train = comp_features.fit_transform(df_train)\n",
    "for df in df_list[1:]:\n",
    "    df = comp_features.transform(df)\n",
    "    \n",
    "NEW_FEATURES_NAMES = [base_feature + '_stat_' + i for i in features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61788\ttest-auc:0.62471\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91326\tvalid-auc:0.89220\ttest-auc:0.87540\n",
      "[100]\ttrain-auc:0.92273\tvalid-auc:0.89602\ttest-auc:0.88306\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-auc:0.92273\tvalid-auc:0.89602\ttest-auc:0.88306\n",
      "\n",
      "roc-auc score of prediction: 0.8666\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES += comp_features.NEW_FEATURE_NAMES\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Новые признаки на базе D15 улучшают точность предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. TransactionAmt - целая и дробная часть, логарифм\n",
    "Выделить дробную часть и целую часть признака TransactionAmt в два отдельных признака. После создать отдельных признак - логарифм от TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_feature(data, name_str):\n",
    "    name_1 = name_str + '_int'\n",
    "    name_2 = name_str + '_frac'\n",
    "    name_3 = name_str + '_log'\n",
    "    data[name_1] = data[name_str].astype(int)\n",
    "    data[name_2] = data[name_str] - data[name_1]\n",
    "    data[name_3] = np.log(data[name_str])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_str = 'TransactionAmt'\n",
    "for df in df_list:\n",
    "    df = transform_feature(df, name_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61788\ttest-auc:0.62471\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91353\tvalid-auc:0.89170\ttest-auc:0.87702\n",
      "[100]\ttrain-auc:0.92317\tvalid-auc:0.89719\ttest-auc:0.88417\n",
      "Stopping. Best iteration:\n",
      "[82]\ttrain-auc:0.92282\tvalid-auc:0.89712\ttest-auc:0.88446\n",
      "\n",
      "roc-auc score of prediction: 0.86543\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES.remove('TransactionAmt')\n",
    "SELECTED_FEATURE_NAMES += ['TransactionAmt_int', 'TransactionAmt_frac', 'TransactionAmt_log']\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Новые признаки не улучшают точность предсказания на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Frequency Encoding P_emaildomain и R_emaildomain\n",
    "Выполнить предварительную подготовку / очистку признаков P_emaildomain и R_emaildomain (что и как делать - остается на ваше усмотрение) и сделать Frequency Encoding для очищенных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_email_address(data, features_list, add_email):\n",
    "    for feature in features_list:\n",
    "        a = list(data[feature].value_counts().keys())\n",
    "        gmail = [i for i in a if i[:5]=='gmail']\n",
    "        yahoo = [i for i in a if i[:5]=='yahoo']\n",
    "        hotmail = [i for i in a if i[:7]=='hotmail']\n",
    "        live = [i for i in a if i[:4]=='live']            \n",
    "        e_mail_list = gmail + yahoo + hotmail + live + add_email\n",
    "        name_str = feature + '_'\n",
    "        data.loc[data[feature].isin(e_mail_list), name_str] = 1\n",
    "        data.loc[data[feature].isnull(), name_str] = -9\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['P_emaildomain', 'R_emaildomain']\n",
    "add_email = ['aol.com', 'anonymous.com'] \n",
    "for df in df_list:\n",
    "    df = classify_email_address(df, features_list, add_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['P_emaildomain_', 'R_emaildomain_']\n",
    "\n",
    "freq_encoder = FrequencyEncoder(features_list)\n",
    "df_train = freq_encoder.fit_transform(df_train)\n",
    "for df in df_list[1:]:\n",
    "    df = freq_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.60237\tvalid-auc:0.61788\ttest-auc:0.62471\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 50 rounds.\n",
      "[50]\ttrain-auc:0.91051\tvalid-auc:0.88766\ttest-auc:0.86895\n",
      "[100]\ttrain-auc:0.91771\tvalid-auc:0.89242\ttest-auc:0.87688\n",
      "Stopping. Best iteration:\n",
      "[72]\ttrain-auc:0.91753\tvalid-auc:0.89265\ttest-auc:0.87711\n",
      "\n",
      "roc-auc score of prediction: 0.8654\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE_NAMES += freq_encoder.NEW_FEATURE_NAMES\n",
    "run_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод:__ Новые признаки не улучшают точность предсказания на тестовой выборке."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
